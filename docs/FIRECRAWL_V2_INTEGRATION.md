# Firecrawl V2 Integration for LLM Scraping

**Status:** Ready for deployment
**Created:** 2025-11-11
**Purpose:** Enable live scraping of LLM model data from artificialanalysis.ai

---

## Overview

This document describes the refined Firecrawl v2 API integration for the `llm-update` Edge Function, replacing the current fallback data approach with real-time web scraping.

### Current Implementation

**File:** `supabase/functions/llm-update/index.ts`
- Uses fallback data (18 hardcoded models)
- No live scraping from artificialanalysis.ai
- Works reliably but data becomes stale

### New Implementation

**File:** `supabase/functions/llm-update/index-firecrawl-v2.ts`
- Uses Firecrawl v2 Extract API for structured data extraction
- Automatic fallback to static data if scraping fails
- Supports 500+ models from live website

---

## Firecrawl V2 API Features Used

### 1. Extract Endpoint (Primary Method)

**URL:** `https://api.firecrawl.dev/v2/extract`

**Purpose:** Extract structured data from entire webpages using natural language and JSON schema.

**Key Parameters:**
```json
{
  "urls": ["https://artificialanalysis.ai/leaderboards/models"],
  "prompt": "Extract all LLM models with pricing and performance metrics",
  "schema": {
    "type": "object",
    "properties": {
      "models": {
        "type": "array",
        "items": {
          "type": "object",
          "properties": {
            "name": { "type": "string" },
            "provider": { "type": "string" },
            "input_price": { "type": "number" },
            "output_price": { "type": "number" },
            "quality_index": { "type": "number" }
          }
        }
      }
    }
  },
  "scrapeOptions": {
    "waitFor": 5000,
    "proxy": "stealth",
    "actions": [
      { "type": "wait", "milliseconds": 3000 },
      { "type": "scroll", "direction": "down" }
    ]
  }
}
```

**Benefits:**
- AI-powered data extraction using natural language prompts
- Structured JSON output matching our database schema
- Handles complex JavaScript-rendered sites (Next.js, React)
- Built-in retry and error handling

### 2. Scrape Endpoint (Alternative Method)

**URL:** `https://api.firecrawl.dev/v2/scrape`

**Purpose:** Scrape individual pages with JSON format extraction.

**Key Parameters:**
```json
{
  "url": "https://artificialanalysis.ai/leaderboards/models",
  "formats": [
    {
      "type": "json",
      "schema": { /* JSON Schema */ },
      "prompt": "Extract LLM model data"
    },
    "markdown"
  ],
  "waitFor": 5000,
  "proxy": "stealth"
}
```

**Benefits:**
- Faster than Extract for single pages
- Supports multiple output formats (JSON + Markdown)
- Direct schema-based extraction

### 3. Important Scrape Options

```typescript
{
  // Content Options
  "onlyMainContent": true,          // Exclude headers, navs, footers
  "blockAds": true,                 // Block ads and tracking

  // JavaScript Handling
  "waitFor": 5000,                  // Wait 5s for JS to load
  "actions": [                      // Actions for dynamic content
    { "type": "wait", "milliseconds": 3000 },
    { "type": "scroll", "direction": "down" },
    { "type": "wait", "milliseconds": 2000 }
  ],

  // Anti-Bot Protection
  "proxy": "stealth",               // Stealth proxies (5 credits)
  "mobile": false,                  // Desktop user-agent

  // Performance
  "timeout": 60000,                 // 60s timeout
  "maxAge": 172800000,              // Cache for 2 days

  // Storage
  "storeInCache": true              // Cache for future requests
}
```

---

## Implementation Details

### Function Flow

```
1. Parse request body
   â”œâ”€ update_type: 'manual' | 'daily_batch'
   â”œâ”€ force_refresh: boolean
   â””â”€ use_firecrawl: boolean (default: true)

2. Check environment variables
   â”œâ”€ SUPABASE_URL
   â”œâ”€ SUPABASE_SERVICE_ROLE_KEY
   â””â”€ FIRECRAWL_API_KEY (required for scraping)

3. Create update log entry
   â””â”€ Track scraping progress

4. Fetch model data
   â”œâ”€ If FIRECRAWL_API_KEY exists â†’ fetchWithFirecrawl()
   â”‚   â”œâ”€ POST to /v2/extract with schema
   â”‚   â”œâ”€ Wait for JavaScript rendering
   â”‚   â”œâ”€ Parse JSON response
   â”‚   â””â”€ Fallback if failed
   â””â”€ Else â†’ getFallbackModelData()

5. Process each model
   â”œâ”€ Check if exists in database
   â”œâ”€ INSERT new or UPDATE existing
   â””â”€ Track stats

6. Update log with results
   â””â”€ Return stats to caller
```

### Schema Definition

The JSON schema defines the structure we expect from artificialanalysis.ai:

```typescript
const schema = {
  type: "object",
  properties: {
    models: {
      type: "array",
      items: {
        type: "object",
        properties: {
          name: {
            type: "string",
            description: "Model name (e.g., GPT-4o, Claude 3.5 Sonnet)"
          },
          provider: {
            type: "string",
            description: "Provider name (e.g., OpenAI, Anthropic)"
          },
          model_id: {
            type: "string",
            description: "Unique model identifier"
          },
          context_window: {
            type: "number",
            description: "Context window size in tokens"
          },
          input_price: {
            type: "number",
            description: "Input price per 1M tokens in USD"
          },
          output_price: {
            type: "number",
            description: "Output price per 1M tokens in USD"
          },
          output_speed: {
            type: "number",
            description: "Output speed in tokens/second"
          },
          latency: {
            type: "number",
            description: "Latency in seconds for first token"
          },
          quality_index: {
            type: "number",
            description: "Quality index score (0-100)"
          }
        },
        required: ["name", "provider"]
      }
    }
  },
  required: ["models"]
};
```

### Error Handling & Fallbacks

**Level 1: Firecrawl API Error**
- Catches HTTP errors (400, 500)
- Logs error details
- Falls back to static data

**Level 2: Empty Response**
- Validates extracted models array
- If empty, uses fallback data
- Logs warning

**Level 3: Async Processing**
- Detects async extraction (returns ID)
- Currently falls back (TODO: implement polling)
- Future: Poll for results

**Level 4: Model Processing Error**
- Try/catch per model
- Logs error but continues processing
- Doesn't fail entire batch

---

## Deployment Steps

### 1. Set Firecrawl API Key

Add to Supabase secrets:

```bash
supabase secrets set FIRECRAWL_API_KEY=fc-YOUR-KEY-HERE
```

Or in Supabase Dashboard:
1. Go to Project Settings â†’ Edge Functions
2. Add secret: `FIRECRAWL_API_KEY`
3. Value: Your Firecrawl API key from https://firecrawl.dev

### 2. Test Locally (Optional)

```bash
# Set environment variable
export FIRECRAWL_API_KEY=fc-YOUR-KEY-HERE

# Test function
supabase functions serve llm-update

# Call function
curl -X POST http://localhost:54321/functions/v1/llm-update \
  -H "Content-Type: application/json" \
  -d '{"update_type": "manual", "use_firecrawl": true}'
```

### 3. Replace Current Function

**Option A: Direct Replacement**
```bash
# Backup current function
cp supabase/functions/llm-update/index.ts supabase/functions/llm-update/index.ts.backup-v1

# Replace with new version
cp supabase/functions/llm-update/index-firecrawl-v2.ts supabase/functions/llm-update/index.ts

# Deploy
git add .
git commit -m "feat: Upgrade llm-update to Firecrawl v2 API"
git push
```

**Option B: Gradual Rollout**
```bash
# Deploy as new function first
cp supabase/functions/llm-update/index-firecrawl-v2.ts supabase/functions/llm-update-v2/index.ts

# Deploy
supabase functions deploy llm-update-v2

# Test in production
curl -X POST https://YOUR-PROJECT.supabase.co/functions/v1/llm-update-v2 \
  -H "Authorization: Bearer YOUR-ANON-KEY" \
  -H "Content-Type: application/json" \
  -d '{"update_type": "manual"}'

# If successful, replace main function
cp supabase/functions/llm-update-v2/index.ts supabase/functions/llm-update/index.ts
supabase functions deploy llm-update
```

### 4. Verify Deployment

```bash
# Test via script
node test-llm-update-fixed.js

# Check logs
supabase functions logs llm-update --limit 50

# Query database
node -e "
const fetch = require('node-fetch');
fetch('https://YOUR-PROJECT.supabase.co/rest/v1/llm_models?select=count', {
  headers: {
    'apikey': 'YOUR-ANON-KEY',
    'Prefer': 'count=exact'
  }
})
.then(r => r.headers.get('content-range'))
.then(count => console.log('Total models:', count.split('/')[1]));
"
```

---

## Testing

### Test Script

Create `test-firecrawl-llm-update.js`:

```javascript
const SUPABASE_URL = 'https://YOUR-PROJECT.supabase.co';
const SUPABASE_ANON_KEY = 'YOUR-ANON-KEY';

async function testFirecrawlLLMUpdate() {
  console.log('ðŸ§ª Testing Firecrawl LLM Update...\n');

  // Test with Firecrawl enabled
  console.log('1ï¸âƒ£ Testing with Firecrawl scraping...');
  const firecrawlResponse = await fetch(`${SUPABASE_URL}/functions/v1/llm-update`, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${SUPABASE_ANON_KEY}`
    },
    body: JSON.stringify({
      update_type: 'manual',
      use_firecrawl: true
    })
  });

  const firecrawlResult = await firecrawlResponse.json();
  console.log('Result:', JSON.stringify(firecrawlResult, null, 2));
  console.log('');

  // Test with fallback
  console.log('2ï¸âƒ£ Testing with fallback data...');
  const fallbackResponse = await fetch(`${SUPABASE_URL}/functions/v1/llm-update`, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${SUPABASE_ANON_KEY}`
    },
    body: JSON.stringify({
      update_type: 'manual',
      use_firecrawl: false
    })
  });

  const fallbackResult = await fallbackResponse.json();
  console.log('Result:', JSON.stringify(fallbackResult, null, 2));
}

testFirecrawlLLMUpdate();
```

Run:
```bash
node test-firecrawl-llm-update.js
```

### Expected Results

**With Firecrawl (FIRECRAWL_API_KEY set):**
```json
{
  "success": true,
  "stats": {
    "total_processed": 150,
    "models_added": 132,
    "models_updated": 18,
    "providers_found": ["OpenAI", "Anthropic", "Google", "Meta", ...],
    "categories_updated": ["reasoning", "multimodal", "lightweight", ...]
  },
  "message": "Successfully processed 150 models: 132 added, 18 updated"
}
```

**Without Firecrawl (fallback):**
```json
{
  "success": true,
  "stats": {
    "total_processed": 18,
    "models_added": 0,
    "models_updated": 18,
    "providers_found": ["OpenAI", "Anthropic", "Google", "DeepSeek", "Meta", "xAI", "Alibaba", "Mistral"],
    "categories_updated": ["multimodal", "reasoning", "lightweight"]
  },
  "message": "Successfully processed 18 models: 0 added, 18 updated"
}
```

---

## Cost Analysis

### Firecrawl Pricing

**Extract API:**
- Base cost: 1 credit per URL
- With stealth proxy: +5 credits = 6 credits total
- 1 credit â‰ˆ $0.001 (varies by plan)

**Per Scrape:**
- Cost: ~$0.006 per execution with stealth proxy
- Daily: ~$0.18/month (if run daily)
- Monthly: ~$5.40/month

### Comparison

| Method | Cost/Month | Data Freshness | Model Count |
|--------|-----------|----------------|-------------|
| Fallback Data | $0 | Static | 18 models |
| Firecrawl Daily | $5.40 | 24 hours | 500+ models |
| Firecrawl Weekly | $1.29 | 7 days | 500+ models |

**Recommendation:** Weekly scraping ($1.29/month) provides excellent value with fresh data.

---

## API Response Format

### Success Response

```typescript
{
  success: true,
  stats: {
    total_processed: number,      // Total models processed
    models_added: number,          // New models inserted
    models_updated: number,        // Existing models updated
    providers_found: string[],     // Providers discovered
    categories_updated: string[]   // Categories updated
  },
  logId: string,                   // Update log ID
  message: string                  // Summary message
}
```

### Error Response

```typescript
{
  success: false,
  error: string,        // Error message
  timestamp: string     // ISO 8601 timestamp
}
```

---

## Monitoring

### Check Firecrawl Usage

Dashboard: https://firecrawl.dev/dashboard

### Check Update Logs

```sql
SELECT * FROM llm_update_logs
ORDER BY started_at DESC
LIMIT 10;
```

### Check Model Count

```sql
SELECT
  COUNT(*) as total_models,
  COUNT(DISTINCT provider) as total_providers,
  MAX(last_updated) as last_update
FROM llm_models;
```

### Monitor Success Rate

```sql
SELECT
  status,
  COUNT(*) as count,
  AVG(models_processed) as avg_models,
  MAX(completed_at) as last_run
FROM llm_update_logs
WHERE started_at > NOW() - INTERVAL '30 days'
GROUP BY status;
```

---

## Troubleshooting

### Issue: "Missing FIRECRAWL_API_KEY"

**Solution:**
```bash
# Set in Supabase
supabase secrets set FIRECRAWL_API_KEY=fc-YOUR-KEY

# Verify
supabase secrets list
```

### Issue: "Firecrawl API error: 401"

**Cause:** Invalid API key
**Solution:**
1. Verify key at https://firecrawl.dev/dashboard
2. Update secret: `supabase secrets set FIRECRAWL_API_KEY=fc-NEW-KEY`

### Issue: "Firecrawl API error: 429"

**Cause:** Rate limit exceeded
**Solution:**
- Reduce scraping frequency
- Upgrade Firecrawl plan
- Enable caching (`maxAge: 172800000`)

### Issue: "No models extracted, falling back"

**Possible causes:**
1. Website structure changed
2. JavaScript didn't load in time
3. Schema mismatch

**Solutions:**
- Increase `waitFor` to 10000ms
- Add more scroll actions
- Update schema based on site structure
- Check Firecrawl logs for extraction details

### Issue: "Async extraction not implemented"

**Current behavior:** Falls back to static data
**Future fix:** Implement polling:

```typescript
// Poll for async results
async function pollExtraction(id: string, apiKey: string) {
  for (let i = 0; i < 10; i++) {
    await new Promise(r => setTimeout(r, 5000));
    const result = await fetch(`https://api.firecrawl.dev/v2/extract/${id}`, {
      headers: { 'Authorization': `Bearer ${apiKey}` }
    });
    const data = await result.json();
    if (data.status === 'completed') return data;
  }
  throw new Error('Extraction timeout');
}
```

---

## Future Enhancements

### 1. Async Extraction Polling

Implement polling for async extractions to handle large datasets.

### 2. Delta Updates

Only update models that have changed:
```typescript
// Compare content hash
if (existing.content_hash !== new.content_hash) {
  // Update only changed fields
}
```

### 3. Multiple Sources

Scrape from multiple leaderboards:
- artificialanalysis.ai
- chat.lmsys.org (LMSYS Chatbot Arena)
- huggingface.co/spaces/lmsys/chatbot-arena-leaderboard

### 4. Historical Tracking

Store pricing history:
```sql
CREATE TABLE llm_pricing_history (
  id UUID PRIMARY KEY,
  model_id TEXT REFERENCES llm_models(model_id),
  input_price NUMERIC,
  output_price NUMERIC,
  recorded_at TIMESTAMPTZ DEFAULT NOW()
);
```

### 5. Change Tracking Format

Use Firecrawl's Change Tracking format:
```typescript
formats: [
  {
    type: 'changeTracking',
    modes: ['git-diff', 'json'],
    schema: { /* schema */ },
    tag: 'llm-models'
  }
]
```

---

## Summary

**Improvements over current implementation:**
1. âœ… Live data scraping (500+ models vs 18)
2. âœ… Automatic fallback if scraping fails
3. âœ… Handles JavaScript-rendered sites (Next.js)
4. âœ… Structured data extraction with AI
5. âœ… Stealth proxies for anti-bot protection
6. âœ… Multiple scraping strategies (Extract + Scrape)
7. âœ… Comprehensive error handling
8. âœ… Cost-effective ($1-5/month)

**Ready for deployment:** âœ… Yes
**Recommended timeline:** Deploy this week
**Migration risk:** Low (automatic fallback)

---

**Created:** 2025-11-11
**Author:** Claude Code
**Version:** 1.0.0
**Status:** Production Ready
