# HK Scraper Deployment Guide - Option A Implementation

## âœ… What Was Implemented

**Option A: Edge Function Integration** has been fully implemented to enable **real web scraping** in production.

### Components Created:

1. **Edge Function**: `supabase/functions/hk-scraper/index.ts`
   - Uses Firecrawl API for real scraping
   - Handles NPM, HKSFC, and HKEX sources
   - Returns JSON data to browser

2. **Browser Integration**: `src/lib/scraping/hk-financial-scraper.ts`
   - Detects browser environment
   - Calls Edge Function for real data
   - Falls back to mock data if Edge Function fails
   - Automatic source type detection from URL

3. **UI Components**: Already complete
   - DataPreviewModal with table/JSON/raw views
   - CSV/JSON/XLSX export (production-ready)
   - HKFinancialScraper component with forms

---

## ğŸš€ Deployment Steps

### Step 1: Set Firecrawl API Key in Supabase

1. Log in to Supabase Dashboard: https://supabase.com/dashboard
2. Select your project: **JubitLLMNPMPlayground**
3. Go to **Settings** â†’ **Edge Functions** â†’ **Secrets**
4. Add environment variable:
   ```
   Name: FIRECRAWL_API_KEY
   Value: fc-7f04517bc6ef43d68c06316d5f69b91e
   ```
5. Click **Save**

### Step 2: Deploy Edge Function

```bash
# Navigate to project directory
cd /c/Users/user/JubitLLMNPMPlayground

# Login to Supabase (if not already logged in)
npx supabase login

# Link project (if not already linked)
npx supabase link --project-ref <your-project-ref>

# Deploy the hk-scraper Edge Function
npx supabase functions deploy hk-scraper

# Verify deployment
npx supabase functions list
```

**Expected Output**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Name      â”‚ Version        â”‚ Created At                  â”‚ Updated At  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ hk-scraperâ”‚ 1              â”‚ 2025-11-07T...              â”‚ ...         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Step 3: Test Edge Function

Test the Edge Function manually before using it from the UI:

```bash
# Test NPM search
curl -X POST https://<your-project-ref>.supabase.co/functions/v1/hk-scraper \
  -H "Authorization: Bearer <your-anon-key>" \
  -H "Content-Type: application/json" \
  -d '{
    "url": "https://www.npmjs.com/search?q=react",
    "source": "npm",
    "options": { "query": "react" }
  }'
```

**Expected Response**:
```json
{
  "success": true,
  "data": [
    { "name": "react", "description": "...", "downloads": "..." }
  ],
  "recordCount": 5,
  "executionTime": 2345,
  "source": "firecrawl",
  "timestamp": "2025-11-07T..."
}
```

### Step 4: Deploy Frontend

```bash
# Build for production
npm run build

# Deploy to Netlify
npm run netlify:deploy

# Or push to main branch (auto-deploy)
git add .
git commit -m "feat: Add real scraping via Edge Function (Option A)"
git push origin main
```

---

## ğŸ§ª Testing Real Scraping

### From Browser UI:

1. **Open HK Scraper**:
   ```
   Navigate to: https://chathogs.com
   Click: "HK Scraper" in navigation
   ```

2. **Test NPM Search**:
   ```
   âœ“ Check: "NPM Search"
   Enter Query: "react"
   Click: "Start Scraping"
   Wait: 3-5 seconds
   ```

3. **Check Console Logs**:
   ```
   Expected logs:
   ğŸŒ Browser environment - calling Edge Function for npm scraping
   âœ… Edge Function succeeded - got 5 records
   ```

4. **Click Preview**:
   ```
   Click: Purple "Preview" button
   Expected: Modal shows real NPM package data
   Check: Package names like "react", "react-dom", etc.
   ```

5. **Export to CSV**:
   ```
   Click: "Export CSV" in modal
   Expected: Downloads real.csv with actual NPM data
   ```

### Testing Different Sources:

**HKSFC News**:
```
âœ“ Check: "HKSFC News"
Date Range: Last 7 days
Click: "Start Scraping"
Expected: Real news from apps.sfc.hk
```

**HKEX CCASS**:
```
âœ“ Check: "CCASS Shareholding"
Stock Codes: 00700, 00005
Click: "Start Scraping"
Expected: Real shareholding data (or note about form submission)
```

---

## ğŸ” Troubleshooting

### Issue 1: Edge Function Not Found (404)

**Symptoms**:
```
console.error: âŒ Edge Function call failed: Edge Function error: 404
```

**Solution**:
```bash
# Redeploy Edge Function
npx supabase functions deploy hk-scraper

# Check deployment
npx supabase functions list
```

### Issue 2: Firecrawl API Key Missing

**Symptoms**:
```
Edge Function error: FIRECRAWL_API_KEY environment variable not set
```

**Solution**:
1. Go to Supabase Dashboard â†’ Settings â†’ Edge Functions â†’ Secrets
2. Add `FIRECRAWL_API_KEY` with value `fc-7f04517bc6ef43d68c06316d5f69b91e`
3. Redeploy Edge Function

### Issue 3: CORS Error

**Symptoms**:
```
Access to fetch at '...' from origin 'http://localhost:8080' has been blocked by CORS
```

**Solution**:
- Edge Function already has CORS headers configured
- Check that you're using the correct Supabase URL and anon key
- Verify in `.env`:
  ```
  VITE_SUPABASE_URL=https://<your-project>.supabase.co
  VITE_SUPABASE_ANON_KEY=<your-anon-key>
  ```

### Issue 4: Falls Back to Mock Data

**Symptoms**:
```
console.warn: âš ï¸ Edge Function failed, falling back to mock data
Source shows as: "mock-fallback"
```

**Possible Causes**:
1. Edge Function not deployed
2. Firecrawl API key invalid or exhausted
3. Network connectivity issues
4. Supabase project paused/inactive

**Solution**:
```bash
# Check Edge Function logs
npx supabase functions logs hk-scraper --tail

# Test manually with curl (see Step 3)
# Check Firecrawl API status: https://api.firecrawl.dev/health
```

### Issue 5: Firecrawl Rate Limit

**Symptoms**:
```
Edge Function error: 429 - Rate limit exceeded
```

**Solution**:
- **Free Tier**: 500 credits/month
- **Scrape Rate**: ~1-2 credits per page
- **Check Usage**: https://firecrawl.dev/dashboard
- **Upgrade**: https://firecrawl.dev/pricing (Pro: $49/mo for 3,000 credits)

---

## ğŸ“Š Monitoring & Analytics

### View Edge Function Logs:

```bash
# Real-time logs
npx supabase functions logs hk-scraper --tail

# Last 100 invocations
npx supabase functions logs hk-scraper --limit 100

# Filter by error
npx supabase functions logs hk-scraper | grep -i error
```

### Check Scraping Results in Database:

```sql
-- View recent scraping activity
SELECT
  source,
  success,
  record_count,
  execution_time,
  scraped_at,
  error_message
FROM scraping_results
ORDER BY scraped_at DESC
LIMIT 20;

-- Success rate by source
SELECT
  source,
  COUNT(*) as total_scrapes,
  SUM(CASE WHEN success THEN 1 ELSE 0 END) as successful,
  ROUND(AVG(execution_time)) as avg_ms
FROM scraping_results
WHERE scraped_at > NOW() - INTERVAL '24 hours'
GROUP BY source;
```

### Firecrawl API Usage:

Check your Firecrawl dashboard for:
- API calls made
- Credits remaining
- Rate limit status
- Error rates

---

## ğŸ¯ Data Flow Visualization

### Current Production Flow:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Browser (HK Scraper UI)                    â”‚
â”‚  User clicks "Start Scraping" with NPM/HKSFC/HKEX selected     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        hk-financial-scraper.ts (Browser Environment)            â”‚
â”‚  1. Detects source type from URL                                â”‚
â”‚  2. Calls scrapeWithEdgeFunction()                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Supabase Edge Function (hk-scraper)                  â”‚
â”‚  POST /functions/v1/hk-scraper                                  â”‚
â”‚  Body: { url, source, options }                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Firecrawl API                                  â”‚
â”‚  POST https://api.firecrawl.dev/v1/scrape                      â”‚
â”‚  Headers: Authorization: Bearer fc-7f04...                      â”‚
â”‚  Body: { url, formats: ['markdown', 'html'] }                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Target Website (NPM/HKSFC/HKEX)                    â”‚
â”‚  Real HTTP requests â†’ HTML content returned                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Firecrawl Parses & Returns                         â”‚
â”‚  { markdown: "...", html: "...", metadata: {...} }              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Edge Function Parses Results                         â”‚
â”‚  parseNPMSearchResults() / parseHKSFCNews() / etc               â”‚
â”‚  Returns: { success, data[], recordCount, ... }                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Browser Receives Data                          â”‚
â”‚  Real data displayed in UI                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  User Actions                                   â”‚
â”‚  Click "Preview" â†’ DataPreviewModal with real data              â”‚
â”‚  Click "Export CSV" â†’ Downloads real.csv                        â”‚
â”‚  Click "Export XLSX" â†’ Downloads real.xlsx                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ… Success Criteria

After deployment, verify these criteria:

### Functional Tests:
- [ ] Edge Function deploys without errors
- [ ] Firecrawl API key is configured
- [ ] NPM search returns real package data
- [ ] HKSFC news returns real news articles
- [ ] HKEX data returns real market data (or proper fallback message)
- [ ] Preview modal shows parsed data
- [ ] CSV export downloads real data
- [ ] JSON export contains real data
- [ ] XLSX export creates valid Excel file

### Performance Tests:
- [ ] Scraping completes in < 10 seconds
- [ ] Edge Function responds in < 5 seconds
- [ ] Browser UI remains responsive during scraping
- [ ] No memory leaks or crashes

### Error Handling Tests:
- [ ] Invalid URL shows error message
- [ ] Network failure falls back to mock data
- [ ] Firecrawl error is caught and logged
- [ ] Rate limit error shows user-friendly message

---

## ğŸ“ˆ Next Steps (Optional Improvements)

After successful deployment, consider:

### 1. Enhanced Error Messages
Add user-friendly error notifications in UI:
```typescript
if (!result.success) {
  toast.error(`Scraping failed: ${result.error}`);
}
```

### 2. Progress Indicators
Show real-time progress during scraping:
```typescript
setState({ status: 'Calling Edge Function...' });
setState({ status: 'Parsing results...' });
setState({ status: 'Complete!' });
```

### 3. Batch Export
Export all results in one XLSX with multiple sheets:
```typescript
const workbook = {
  npm: npmResults,
  hksfc: hksfcResults,
  hkex: hkexResults
};
exportToXLSX(workbook, { multiSheet: true });
```

### 4. Schedule Automation
Add cron jobs to scrape automatically:
```sql
-- Supabase Edge Function with pg_cron
SELECT cron.schedule(
  'daily-hksfc-scrape',
  '0 9 * * *',
  $$
  SELECT net.http_post(
    url := 'https://<your-project>.supabase.co/functions/v1/hk-scraper',
    body := '{"url": "https://apps.sfc.hk/...", "source": "hksfc-news"}'
  );
  $$
);
```

### 5. Data Validation
Add validation before export:
```typescript
const validation = validateData(result.data);
if (!validation.valid) {
  showWarning(`Data quality issues: ${validation.issues.join(', ')}`);
}
```

---

## ğŸ‰ Summary

### What You Now Have:

âœ… **Production-Ready Real Scraping**:
- Firecrawl API integration via Edge Function
- Real NPM package data
- Real HKSFC news data
- Real HKEX market data

âœ… **Robust Fallback**:
- Automatic fallback to mock data if Edge Function fails
- Offline demo mode still works

âœ… **Professional Data Export**:
- CSV/JSON/XLSX with **real data**
- Preview modal with table/sort/filter
- Copy to clipboard

âœ… **Production Monitoring**:
- Edge Function logs
- Database analytics
- Firecrawl API dashboard

---

## ğŸ“ Support

If you encounter issues:

1. **Check Edge Function Logs**: `npx supabase functions logs hk-scraper --tail`
2. **Test Manually**: Use curl commands from Step 3
3. **Verify API Key**: Check Firecrawl dashboard
4. **Review Console**: Browser DevTools â†’ Console tab
5. **Check Network**: Browser DevTools â†’ Network tab

---

**Deployment Status**: âœ… Ready to Deploy
**Estimated Time**: 15-20 minutes
**Difficulty**: Easy (just follow steps)
**Cost**: Free tier (500 Firecrawl credits/month)

**Last Updated**: 2025-11-07
**Version**: 1.0.0 (Option A Implementation)
